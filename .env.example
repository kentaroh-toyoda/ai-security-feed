# LLM Configuration
# Choose your LLM provider: openrouter, openai, anthropic, etc.
LLM_PROVIDER=openrouter

# Your LLM model (depends on provider)
# For OpenRouter: openai/gpt-5-mini, anthropic/claude-3-haiku, etc.
LLM_MODEL=openai/gpt-5-mini

# API Key for your LLM provider
LLM_API_KEY=your_api_key_here

# Optional: Custom base URL for LLM provider
# LLM_BASE_URL=https://openrouter.ai/api/v1

# Application Settings
# OUTPUT_FILE=articles.rss
# REQUEST_TIMEOUT=30
# MAX_ARTICLES_PER_SOURCE=50

# Page Loading Configuration
# Enable waiting for dynamic content to load (default: true)
# ENABLE_PAGE_LOAD_WAIT=true

# Time to wait in seconds before processing page content (default: 30)
# PAGE_LOAD_WAIT_TIME=30

# Browser-based Dynamic Content Fetching
# Enable intelligent browser fetching for dynamic content (default: true)
# BROWSER_ENABLED=true

# Browser type: chrome or firefox (default: chrome)
# BROWSER_TYPE=chrome

# Run browser in headless mode (default: true)
# BROWSER_HEADLESS=true

# Initial wait time after page load before scrolling (default: 5)
# BROWSER_WAIT_TIME=5

# Number of scroll attempts for infinite scroll (default: 3)
# BROWSER_SCROLL_ATTEMPTS=3

# Wait time between scrolls in seconds (default: 2)
# BROWSER_MAX_SCROLL_WAIT=2

# Timeout for static fetch attempt before trying browser (default: 30)
# STATIC_FETCH_TIMEOUT=30
