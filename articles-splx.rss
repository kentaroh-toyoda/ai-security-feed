<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Web Article Collection</title>
    <link>https://your-domain.com/</link>
    <description>Collected and summarized articles from various sources</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>Web Article Collection Agent</generator>
    <language>en</language>
    <lastBuildDate>Sat, 30 Aug 2025 23:37:30 +0000</lastBuildDate>
    <item>
      <title>DeepSeek-r1 vs. OpenAI-o1: The Ultimate Security Showdown</title>
      <link>https://splx.ai/blog/deepseek-r1-vs-openai-o1-the-ultimate-security-showdown</link>
      <description>The article compares DeepSeek-r1 and OpenAI-o1, focusing on their security features and performance in safeguarding data. It provides an in-depth analysis of their strengths and weaknesses to determine which model offers superior security capabilities.</description>
      <guid isPermaLink="false">https://splx.ai/blog/deepseek-r1-vs-openai-o1-the-ultimate-security-showdown</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Machine Learning Models</category>
      <category>Technology Comparison</category>
      <pubDate>Sat, 30 Aug 2025 23:38:04 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI and Number™ Partner to Enable the Secure Development of AI Assistants</title>
      <link>https://splx.ai/blog/splxai-and-numbertm-partner-to-enable-the-secure-development-of-ai-assistants</link>
      <description>SplxAI and Number™ have formed a partnership aimed at enhancing the secure development of AI assistants. This collaboration focuses on integrating advanced security measures to protect AI systems during their creation and deployment.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-and-numbertm-partner-to-enable-the-secure-development-of-ai-assistants</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Technology Partnerships</category>
      <category>AI Development</category>
      <category>Software Security</category>
      <pubDate>Sat, 30 Aug 2025 23:38:03 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Mastering AI Red Teaming: Strategies for Securing AI Systems</title>
      <link>https://splx.ai/blog/mastering-ai-red-teaming-strategies-for-securing-ai-systems</link>
      <description>The article explores effective strategies for AI red teaming, emphasizing the importance of simulated adversarial attacks to identify vulnerabilities in AI systems. It provides insights into methodologies and best practices to enhance the security and robustness of AI technologies.</description>
      <guid isPermaLink="false">https://splx.ai/blog/mastering-ai-red-teaming-strategies-for-securing-ai-systems</guid>
      <category>AI Security</category>
      <category>Red Teaming</category>
      <category>Cybersecurity</category>
      <category>Artificial Intelligence</category>
      <category>Risk Management</category>
      <pubDate>Sat, 30 Aug 2025 23:38:02 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>AI Transparency: Connecting AI Red Teaming and Compliance</title>
      <link>https://splx.ai/blog/ai-transparency-connecting-ai-red-teaming-and-compliance</link>
      <description>The article discusses the importance of AI transparency by linking AI red teaming practices with regulatory compliance efforts. It highlights how red teaming can identify vulnerabilities and biases in AI systems, thereby ensuring they meet compliance standards and promote ethical AI deployment.</description>
      <guid isPermaLink="false">https://splx.ai/blog/ai-transparency-connecting-ai-red-teaming-and-compliance</guid>
      <category>AI Transparency</category>
      <category>AI Red Teaming</category>
      <category>Regulatory Compliance</category>
      <category>Ethical AI</category>
      <category>AI Risk Management</category>
      <pubDate>Sat, 30 Aug 2025 23:38:01 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Introducing Agentic Radar: The New OSS Tool for AI Workflow Transparency</title>
      <link>https://splx.ai/blog/introducing-agentic-radar-the-new-oss-tool-for-ai-workflow-transparency</link>
      <description>Agentic Radar is a newly introduced open-source software (OSS) tool designed to enhance transparency in AI workflows. Developed by the SplxAI team, it aims to provide clearer insights into the operations and decision-making processes of AI systems. This tool supports better understanding and trust in AI applications by making their workflows more interpretable.</description>
      <guid isPermaLink="false">https://splx.ai/blog/introducing-agentic-radar-the-new-oss-tool-for-ai-workflow-transparency</guid>
      <category>Artificial Intelligence</category>
      <category>Open Source Software</category>
      <category>AI Transparency</category>
      <category>Workflow Management</category>
      <category>Technology Tools</category>
      <pubDate>Sat, 30 Aug 2025 23:38:00 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Understanding Agentic AI: What It Is and How to Build It Securely</title>
      <link>https://splx.ai/blog/what-is-agentic-ai-and-how-to-build-it-securely</link>
      <description>The article explains the concept of agentic AI, which refers to artificial intelligence systems capable of autonomous decision-making and goal-directed behavior. It also discusses best practices and security measures necessary to build such AI systems safely and responsibly.</description>
      <guid isPermaLink="false">https://splx.ai/blog/what-is-agentic-ai-and-how-to-build-it-securely</guid>
      <category>Artificial Intelligence</category>
      <category>Agentic AI</category>
      <category>AI Security</category>
      <category>Autonomous Systems</category>
      <category>AI Development</category>
      <pubDate>Sat, 30 Aug 2025 23:37:59 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Enhancing AI Transparency: Scanning CrewAI Workflows with Agentic Radar</title>
      <link>https://splx.ai/blog/enhancing-ai-transparency-scanning-crewai-workflows-with-agentic-radar</link>
      <description>The article discusses a new feature called Agentic Radar designed to improve transparency in AI workflows within CrewAI. By scanning workflows, Agentic Radar helps users better understand and monitor AI decision-making processes, enhancing trust and accountability. This update aims to make AI operations more interpretable and manageable for users.</description>
      <guid isPermaLink="false">https://splx.ai/blog/enhancing-ai-transparency-scanning-crewai-workflows-with-agentic-radar</guid>
      <category>Artificial Intelligence</category>
      <category>AI Transparency</category>
      <category>Workflow Management</category>
      <category>Product Updates</category>
      <category>Technology</category>
      <pubDate>Sat, 30 Aug 2025 23:37:58 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Scanning n8n Workflows with Agentic Radar</title>
      <link>https://splx.ai/blog/scanning-n8n-workflows-with-agentic-radar</link>
      <description>The article introduces a new product update that enables scanning of n8n workflows using Agentic Radar, enhancing workflow analysis and automation capabilities. It highlights the integration's benefits for improving workflow efficiency and monitoring.</description>
      <guid isPermaLink="false">https://splx.ai/blog/scanning-n8n-workflows-with-agentic-radar</guid>
      <category>Automation</category>
      <category>Workflow Management</category>
      <category>Product Update</category>
      <category>Software Integration</category>
      <pubDate>Sat, 30 Aug 2025 23:37:58 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI Closes $7M Seed Funding Round to Help Organizations Secure Agentic AI Systems</title>
      <link>https://splx.ai/blog/splxai-closes-7m-seed-funding-round-to-help-organizations-secure-agentic-ai-systems</link>
      <description>SplxAI has secured $7 million in a seed funding round aimed at enhancing the security of agentic AI systems for organizations. The funding will support the development of technologies to safeguard autonomous AI agents against emerging threats.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-closes-7m-seed-funding-round-to-help-organizations-secure-agentic-ai-systems</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Startup Funding</category>
      <category>Technology Innovation</category>
      <pubDate>Sat, 30 Aug 2025 23:37:56 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Exploiting Agentic Workflows: Prompt Injections in Multi-Agent AI Systems</title>
      <link>https://splx.ai/blog/exploiting-agentic-workflows-prompt-injections-in-multi-agent-ai-systems</link>
      <description>The article explores vulnerabilities in multi-agent AI systems, specifically focusing on how prompt injections can be exploited within agentic workflows. It discusses the implications of these security flaws and suggests potential mitigation strategies to enhance the robustness of AI interactions.</description>
      <guid isPermaLink="false">https://splx.ai/blog/exploiting-agentic-workflows-prompt-injections-in-multi-agent-ai-systems</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Multi-Agent Systems</category>
      <category>Prompt Engineering</category>
      <category>AI Safety</category>
      <pubDate>Sat, 30 Aug 2025 23:37:55 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>OpenAI Agents SDK: Transparent Workflows with Agentic Radar</title>
      <link>https://splx.ai/blog/openai-agents-sdk-transparent-workflows-with-agentic-radar</link>
      <description>The OpenAI Agents SDK introduces Agentic Radar, a tool designed to enhance transparency in AI workflows by providing clear visibility into agent actions and decision-making processes. This update aims to improve user trust and debugging capabilities by making agent operations more interpretable and manageable.</description>
      <guid isPermaLink="false">https://splx.ai/blog/openai-agents-sdk-transparent-workflows-with-agentic-radar</guid>
      <category>Artificial Intelligence</category>
      <category>Software Development</category>
      <category>OpenAI</category>
      <category>AI Transparency</category>
      <category>Developer Tools</category>
      <pubDate>Sat, 30 Aug 2025 23:37:54 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI Enables CISOs to Secure Agentic AI with Industry’s First Agentic Workflow Transparency Tool</title>
      <link>https://splx.ai/blog/splxai-enables-cisos-to-secure-agentic-ai-with-industry-first-agentic-workflow-transparency-tool</link>
      <description>SplxAI has introduced the industry's first Agentic Workflow Transparency Tool designed to help Chief Information Security Officers (CISOs) secure agentic AI systems. This innovation aims to enhance visibility and control over AI workflows, addressing security challenges associated with autonomous AI operations.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-enables-cisos-to-secure-agentic-ai-with-industry-first-agentic-workflow-transparency-tool</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Enterprise Technology</category>
      <category>AI Transparency</category>
      <category>Information Security</category>
      <pubDate>Sat, 30 Aug 2025 23:37:53 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Agentic Radar Now Detects MCP Servers in Agentic Workflows</title>
      <link>https://splx.ai/blog/agentic-radar-now-detects-mcp-servers-in-agentic-workflows</link>
      <description>The latest update to Agentic Radar introduces the capability to detect MCP servers within agentic workflows, enhancing monitoring and management efficiency. This feature aims to improve workflow automation by providing better visibility into server interactions.</description>
      <guid isPermaLink="false">https://splx.ai/blog/agentic-radar-now-detects-mcp-servers-in-agentic-workflows</guid>
      <category>Product Update</category>
      <category>Software Development</category>
      <category>Automation</category>
      <category>IT Infrastructure</category>
      <pubDate>Sat, 30 Aug 2025 23:37:52 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>OpenPolicy and SplxAI Partner to Close the Gap Between Emerging AI Policies and AI Security</title>
      <link>https://splx.ai/blog/openpolicy-and-splxai-partnership</link>
      <description>OpenPolicy and SplxAI have formed a partnership aimed at bridging the gap between emerging AI policies and AI security measures. This collaboration seeks to ensure that AI systems comply with new regulations while maintaining robust security standards.</description>
      <guid isPermaLink="false">https://splx.ai/blog/openpolicy-and-splxai-partnership</guid>
      <category>AI Policy</category>
      <category>AI Security</category>
      <category>Technology Partnerships</category>
      <category>Regulatory Compliance</category>
      <category>Artificial Intelligence</category>
      <pubDate>Sat, 30 Aug 2025 23:37:50 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>The Missing GPT-4.1 Safety Report: Switch from GPT-4o to GPT-4.1 with Caution</title>
      <link>https://splx.ai/blog/the-missing-gpt-4-1-safety-report</link>
      <description>The article discusses the absence of a comprehensive safety report for GPT-4.1, advising users to exercise caution when transitioning from GPT-4o to GPT-4.1. It highlights potential risks and the need for thorough evaluation before adopting the newer model.</description>
      <guid isPermaLink="false">https://splx.ai/blog/the-missing-gpt-4-1-safety-report</guid>
      <category>Artificial Intelligence</category>
      <category>Machine Learning</category>
      <category>AI Safety</category>
      <category>Technology Research</category>
      <category>Software Updates</category>
      <pubDate>Sat, 30 Aug 2025 23:37:48 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI Adds Native Support for Glean AI Assistants and Agents</title>
      <link>https://splx.ai/blog/splxai-supports-glean-ai-assistants-and-agents</link>
      <description>SplxAI has introduced native support for Glean AI Assistants and Agents, enhancing its platform's capabilities for AI-driven assistance. This update aims to improve integration and user experience by seamlessly incorporating Glean's AI technologies.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-supports-glean-ai-assistants-and-agents</guid>
      <category>Artificial Intelligence</category>
      <category>Product Update</category>
      <category>Software Integration</category>
      <category>AI Assistants</category>
      <category>Technology</category>
      <pubDate>Sat, 30 Aug 2025 23:37:47 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Harden the System Prompts in AI Workflows with Agentic Radar</title>
      <link>https://splx.ai/blog/agentic-radar-now-scans-and-hardens-system-prompts-in-agentic-workflows</link>
      <description>The article discusses the introduction of Agentic Radar, a tool designed to strengthen system prompts within AI workflows. It highlights how this update enhances prompt reliability and security, ensuring more robust and controlled AI interactions.</description>
      <guid isPermaLink="false">https://splx.ai/blog/agentic-radar-now-scans-and-hardens-system-prompts-in-agentic-workflows</guid>
      <category>Artificial Intelligence</category>
      <category>AI Workflows</category>
      <category>Prompt Engineering</category>
      <category>Product Updates</category>
      <category>AI Security</category>
      <pubDate>Sat, 30 Aug 2025 23:37:46 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI Is Now Available In The Microsoft Azure Marketplace</title>
      <link>https://splx.ai/blog/splxai-is-now-available-in-the-microsoft-azure-marketplace</link>
      <description>SplxAI has been launched on the Microsoft Azure Marketplace, enabling users to access its AI capabilities through Microsoft's cloud platform. This integration aims to enhance accessibility and scalability for businesses leveraging AI solutions.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-is-now-available-in-the-microsoft-azure-marketplace</guid>
      <category>Artificial Intelligence</category>
      <category>Cloud Computing</category>
      <category>Microsoft Azure</category>
      <category>Technology Integration</category>
      <category>Software Marketplace</category>
      <pubDate>Sat, 30 Aug 2025 23:37:45 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>OpenAI Used Agentic Radar to Judge Europe’s Largest AI Hackathon – Here Are The Results</title>
      <link>https://splx.ai/blog/openai-aitinkerers-hackathon-agentic-radar-insights</link>
      <description>OpenAI utilized its Agentic Radar technology to evaluate projects at Europe’s largest AI hackathon, providing an innovative approach to judging AI competitions. The article details the results and insights gained from applying this AI-driven assessment tool during the event.</description>
      <guid isPermaLink="false">https://splx.ai/blog/openai-aitinkerers-hackathon-agentic-radar-insights</guid>
      <category>Artificial Intelligence</category>
      <category>Hackathons</category>
      <category>Technology Competitions</category>
      <category>AI Evaluation Tools</category>
      <category>OpenAI</category>
      <pubDate>Sat, 30 Aug 2025 23:37:44 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Scanning AutoGen Workflows with Agentic Radar</title>
      <link>https://splx.ai/blog/scanning-autogen-workflows-with-agentic-radar</link>
      <description>The article discusses the introduction of Agentic Radar, a tool designed to scan and analyze AutoGen workflows for improved efficiency and error detection. It highlights how this update enhances workflow management by providing real-time insights and automated monitoring capabilities.</description>
      <guid isPermaLink="false">https://splx.ai/blog/scanning-autogen-workflows-with-agentic-radar</guid>
      <category>Product Update</category>
      <category>Automation</category>
      <category>Workflow Management</category>
      <category>Artificial Intelligence</category>
      <category>Software Tools</category>
      <pubDate>Sat, 30 Aug 2025 23:37:43 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Is Single-Message Jailbreaking Dead? What This Means for AI Security</title>
      <link>https://splx.ai/blog/is-single-message-jailbreaking-dead-what-this-means-for-ai-security</link>
      <description>The article explores the decline of single-message jailbreaking techniques in AI systems, analyzing how advancements in AI security measures have rendered these methods less effective. It discusses the implications for future AI security strategies and the evolving landscape of AI vulnerability exploitation.</description>
      <guid isPermaLink="false">https://splx.ai/blog/is-single-message-jailbreaking-dead-what-this-means-for-ai-security</guid>
      <category>AI Security</category>
      <category>Machine Learning</category>
      <category>Cybersecurity</category>
      <category>AI Ethics</category>
      <category>Technology Trends</category>
      <pubDate>Sat, 30 Aug 2025 23:37:42 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI Adds LLM Benchmarks to Help Enterprises Select the Most Secure Models</title>
      <link>https://splx.ai/blog/splxai-adds-llm-benchmarks-to-help-enterprises-select-the-most-secure-models</link>
      <description>SplxAI has introduced new benchmarks for large language models (LLMs) aimed at helping enterprises evaluate and select the most secure AI models. These benchmarks focus on assessing security aspects to ensure safer deployment of LLMs in business environments.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-adds-llm-benchmarks-to-help-enterprises-select-the-most-secure-models</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Enterprise Technology</category>
      <category>Machine Learning</category>
      <category>AI Benchmarking</category>
      <pubDate>Sat, 30 Aug 2025 23:37:41 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>OpenAI o3-pro vs. GPT-4o: Unreasonable Amount of Reasoning?</title>
      <link>https://splx.ai/blog/openai-o3-pro-vs-gpt-4o-performance-review</link>
      <description>The article compares OpenAI's o3-pro and GPT-4o models, focusing on their reasoning capabilities and performance differences. It explores whether the enhanced reasoning abilities in these models are justified or excessive, providing insights into their practical applications and limitations.</description>
      <guid isPermaLink="false">https://splx.ai/blog/openai-o3-pro-vs-gpt-4o-performance-review</guid>
      <category>Artificial Intelligence</category>
      <category>Machine Learning</category>
      <category>Natural Language Processing</category>
      <category>AI Model Comparison</category>
      <category>Reasoning in AI</category>
      <pubDate>Sat, 30 Aug 2025 23:37:40 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SplxAI Announces Partnership with Databricks to Provide Security Across the Full Agentic AI Lifecycle</title>
      <link>https://splx.ai/blog/splxai-databricks-technology-partnership</link>
      <description>SplxAI has partnered with Databricks to enhance security measures throughout the entire agentic AI lifecycle. This collaboration aims to provide comprehensive protection and governance for AI systems from development to deployment.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splxai-databricks-technology-partnership</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Partnerships</category>
      <category>AI Lifecycle Management</category>
      <category>Technology</category>
      <pubDate>Sat, 30 Aug 2025 23:37:39 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Grok 4 Without Guardrails? Total Safety Failure. We Tested and Fixed Elon’s New Model.</title>
      <link>https://splx.ai/blog/grok-4-security-testing</link>
      <description>The article evaluates Grok 4, Elon Musk's latest AI model, highlighting significant safety issues when operated without guardrails. The author details the testing process and the subsequent improvements made to address these safety failures.</description>
      <guid isPermaLink="false">https://splx.ai/blog/grok-4-security-testing</guid>
      <category>Artificial Intelligence</category>
      <category>Safety Testing</category>
      <category>Technology Review</category>
      <category>AI Ethics</category>
      <category>Elon Musk</category>
      <pubDate>Sat, 30 Aug 2025 23:37:38 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>We Broke Kimi K2, the New Open Model, in Minutes. Can It Be Made Safe?</title>
      <link>https://splx.ai/blog/kimi-k2-safety-test</link>
      <description>The article explores the vulnerabilities of the Kimi K2, a new open model device, which was compromised within minutes during testing. It discusses the potential risks associated with such open models and considers whether effective safety measures can be implemented to secure them.</description>
      <guid isPermaLink="false">https://splx.ai/blog/kimi-k2-safety-test</guid>
      <category>Technology</category>
      <category>Cybersecurity</category>
      <category>Product Safety</category>
      <category>Open Source Hardware</category>
      <pubDate>Sat, 30 Aug 2025 23:37:37 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SPLX Launches Next Phase of Growth by Unveiling End-to-End Security Platform for AI</title>
      <link>https://splx.ai/blog/comprehensive-ai-security-launch</link>
      <description>SPLX has announced the launch of a comprehensive end-to-end security platform designed specifically for artificial intelligence applications. This move marks a significant step in the company's growth strategy, aiming to address the unique security challenges posed by AI technologies.</description>
      <guid isPermaLink="false">https://splx.ai/blog/comprehensive-ai-security-launch</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Technology Innovation</category>
      <category>Enterprise Software</category>
      <category>Business Growth</category>
      <pubDate>Sat, 30 Aug 2025 23:37:36 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Simplify Red Team Results &amp; Speed Up Remediation: SPLX Launches “Analyze with AI"</title>
      <link>https://splx.ai/blog/analyze-red-teaming-data</link>
      <description>SPLX has introduced a new feature called “Analyze with AI” designed to simplify the analysis of Red Team exercise results and accelerate the remediation process. This AI-powered tool aims to enhance efficiency by providing faster insights and actionable recommendations for security teams.</description>
      <guid isPermaLink="false">https://splx.ai/blog/analyze-red-teaming-data</guid>
      <category>Cybersecurity</category>
      <category>Artificial Intelligence</category>
      <category>Red Teaming</category>
      <category>Security Automation</category>
      <category>Product Updates</category>
      <pubDate>Sat, 30 Aug 2025 23:37:35 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>GLM-4.5. Can It Pass the Enterprise AI Security Test Where Kimi K2 Failed?</title>
      <link>https://splx.ai/blog/glm45-vs-kimik2-safety-test</link>
      <description>The article evaluates GLM-4.5's performance in enterprise AI security, comparing it to the previously tested Kimi K2 model which failed certain security benchmarks. It discusses whether GLM-4.5 can overcome these challenges and meet the stringent requirements of enterprise-level AI security.</description>
      <guid isPermaLink="false">https://splx.ai/blog/glm45-vs-kimik2-safety-test</guid>
      <category>Artificial Intelligence</category>
      <category>Enterprise Security</category>
      <category>AI Security Testing</category>
      <category>Machine Learning Models</category>
      <category>Technology Research</category>
      <pubDate>Sat, 30 Aug 2025 23:37:34 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>The AI Agents That Trust Too Much: Are Your Agentic Workflows Vulnerable - PART 1</title>
      <link>https://splx.ai/blog/agentic-ai-trust-breakdown</link>
      <description>The article explores the vulnerabilities in agentic AI workflows caused by excessive trust placed in AI agents. It highlights potential risks and challenges in relying on autonomous AI systems for decision-making and workflow automation. This is the first part of a series analyzing these security and reliability concerns.</description>
      <guid isPermaLink="false">https://splx.ai/blog/agentic-ai-trust-breakdown</guid>
      <category>Artificial Intelligence</category>
      <category>AI Security</category>
      <category>Agentic Workflows</category>
      <category>Automation</category>
      <category>Risk Management</category>
      <pubDate>Sat, 30 Aug 2025 23:37:33 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Can Claude Opus 4.1 Be Secured for Enterprise Use? Our Red Teaming Results</title>
      <link>https://splx.ai/blog/opus-4-1-security-evaluation</link>
      <description>The article presents the findings from a red teaming exercise conducted on Claude Opus 4.1 to evaluate its security posture for enterprise deployment. It discusses vulnerabilities identified, mitigation strategies, and overall recommendations for securing the AI system in corporate environments.</description>
      <guid isPermaLink="false">https://splx.ai/blog/opus-4-1-security-evaluation</guid>
      <category>Cybersecurity</category>
      <category>AI Security</category>
      <category>Enterprise Technology</category>
      <category>Red Teaming</category>
      <category>Risk Assessment</category>
      <pubDate>Sat, 30 Aug 2025 23:37:32 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>SPLX and COONTEC Partner to Secure Enterprise AI in South Korea</title>
      <link>https://splx.ai/blog/splx-coontec-partnership</link>
      <description>SPLX and COONTEC have formed a partnership to enhance the security of enterprise AI solutions in South Korea. This collaboration aims to address growing cybersecurity challenges associated with AI deployment in the region's corporate sector.</description>
      <guid isPermaLink="false">https://splx.ai/blog/splx-coontec-partnership</guid>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>Enterprise Technology</category>
      <category>South Korea</category>
      <category>Business Partnerships</category>
      <pubDate>Sat, 30 Aug 2025 23:37:31 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>GPT-5 Red Teaming Results</title>
      <link>https://splx.ai/blog/gpt-5-red-teaming-results</link>
      <guid isPermaLink="false">https://splx.ai/blog/gpt-5-red-teaming-results</guid>
      <pubDate>Sat, 30 Aug 2025 23:37:30 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
  </channel>
</rss>
