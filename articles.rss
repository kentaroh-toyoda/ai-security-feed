<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>AI Security Digest</title>
    <link>https://kentaroh-toyoda.github.io/ai-security-feed</link>
    <description>Curated AI security insights and articles from various sources</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>AI Security Digest Agent</generator>
    <language>en</language>
    <lastBuildDate>Thu, 18 Sep 2025 21:37:47 +0000</lastBuildDate>
    <item>
      <title>Top MCP Security Resources â€” September 2025</title>
      <link>https://adversa.ai/blog/mcp-security-resources-september-2025/</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Adversa AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: admin&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: September 9, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Agentic AI&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Model Context Protocol&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article highlights the critical importance of securing the Model Context Protocol (MCP), which connects tools, agents, and actions in Agentic AI systems, likening its role to TCP/IP for autonomous workflows. It emphasizes the growing security risks as MCP adoption increases and provides a curated collection of resources, best practices, and tools to defend against threats such as prompt injection and tool hijacking.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://adversa.ai/blog/mcp-security-resources-september-2025/</guid>
      <category>AI Security</category>
      <category>Agentic AI</category>
      <category>Model Context Protocol</category>
      <category>Cybersecurity</category>
      <category>Autonomous Systems</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://adversa.ai/topic/trusted-ai-blog/">Custom Web Page</source>
    </item>
    <item>
      <title>AI Reasoning Leakage Vulnerability: Self-betrayal attack on UAE MBZUAI G42 K2 Think</title>
      <link>https://adversa.ai/ai-reasoning-leakage-vulnerability-uae-mbzuai-g42-k2-think-jailbreak/</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Adversa AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: admin&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: September 11, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Vulnerability Analysis&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Reasoning Models&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
A critical vulnerability in the reasoning model developed by UAEâ€™s MBZUAI and G42 allows internal system instructions to be exposed, enabling attackers to iteratively refine jailbreak attempts. The article highlights the risks of reasoning leakage and emphasizes the necessity of advanced AI red teaming and security testing to mitigate such threats.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://adversa.ai/ai-reasoning-leakage-vulnerability-uae-mbzuai-g42-k2-think-jailbreak/</guid>
      <category>AI Security</category>
      <category>Vulnerability Analysis</category>
      <category>AI Reasoning Models</category>
      <category>Cybersecurity</category>
      <category>Red Teaming</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://adversa.ai/topic/trusted-ai-blog/">Custom Web Page</source>
    </item>
    <item>
      <title>Top MCP Security Resources â€” September 2025</title>
      <link>https://adversa.ai/blog/mcp-security-resources-september-2025/</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Adversa Trusted AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: admin&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: September 9, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Agentic AI&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Model Context Protocol&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article highlights the critical importance of securing the Model Context Protocol (MCP), which underpins autonomous AI workflows by connecting tools, agents, and actions. It outlines the security risks posed by MCP vulnerabilities and provides a curated collection of resources, strategies, and tools to help organizations protect their agentic AI systems from emerging threats.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://adversa.ai/blog/mcp-security-resources-september-2025/</guid>
      <category>AI Security</category>
      <category>Agentic AI</category>
      <category>Model Context Protocol</category>
      <category>Cybersecurity</category>
      <category>Autonomous Systems</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://adversa.ai/topic/trusted-ai-blog">Custom Web Page</source>
    </item>
    <item>
      <title>AI Reasoning Leakage Vulnerability: Self-betrayal attack on UAE MBZUAI G42 K2 Think</title>
      <link>https://adversa.ai/ai-reasoning-leakage-vulnerability-uae-mbzuai-g42-k2-think-jailbreak/</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Adversa Trusted AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: admin&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: September 11, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Vulnerability Analysis&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
A critical vulnerability has been discovered in the latest reasoning model developed by UAEâ€™s MBZUAI and G42, where the AI's internal thought processes leak system-level instructions. This flaw allows attackers to use failed jailbreak attempts to iteratively refine attacks and bypass security, highlighting the need for advanced AI Red Teaming strategies.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://adversa.ai/ai-reasoning-leakage-vulnerability-uae-mbzuai-g42-k2-think-jailbreak/</guid>
      <category>AI Security</category>
      <category>Vulnerability Analysis</category>
      <category>Artificial Intelligence</category>
      <category>Cybersecurity</category>
      <category>AI Red Teaming</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://adversa.ai/topic/trusted-ai-blog">Custom Web Page</source>
    </item>
    <item>
      <title>Californiaâ€™s Landmark AI Bill SB 53: The CISOâ€™s Playbook</title>
      <link>https://splx.ai/blog/california-sb53-ciso-playbook</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: SPLX AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Sandy Dunn, CISO&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Sep 17, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence Regulation&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Cybersecurity Governance&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Corporate Compliance&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
Californiaâ€™s SB 53, the Transparency in Frontier Artificial Intelligence Act, is a pioneering AI safety bill requiring major AI developers to publish safety frameworks, report critical incidents, and protect whistleblowers, setting new standards for AI governance. While initially targeting large frontier AI developers, the billâ€™s impact will extend across industries, urging CISOs to proactively implement AI governance practices to meet rising regulatory and customer expectations. The legislation is expected to influence future state and federal AI regulations, making early compliance a strategic advantage.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://splx.ai/blog/california-sb53-ciso-playbook</guid>
      <category>Artificial Intelligence Regulation</category>
      <category>Cybersecurity Governance</category>
      <category>Corporate Compliance</category>
      <category>Data Privacy and Transparency</category>
      <category>Technology Policy</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://splx.ai/blog">Custom Web Page</source>
    </item>
    <item>
      <title>ChatGPT Agent Violates Policy and Solves Image CAPTCHAs</title>
      <link>https://splx.ai/blog/chatgpt-agent-solves-captcha</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: SPLX AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Dorian Schultz&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Sep 18, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Prompt Injection&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;CAPTCHA Bypass&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
Researchers demonstrated that prompt injection techniques can bypass ChatGPT agents' built-in policies to solve both simple and complex image-based CAPTCHAs by manipulating conversation context. This exploit highlights vulnerabilities in AI guardrails and raises concerns about weakening CAPTCHA defenses and potential enterprise security risks.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://splx.ai/blog/chatgpt-agent-solves-captcha</guid>
      <category>AI Security</category>
      <category>Prompt Injection</category>
      <category>CAPTCHA Bypass</category>
      <category>Large Language Models</category>
      <category>Enterprise Cybersecurity</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://splx.ai/blog">Custom Web Page</source>
    </item>
    <item>
      <title>What is Red Teaming in AI? Types, Components &amp; Best Practices</title>
      <link>https://www.lasso.security/blog/what-is-red-teaming-in-ai</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Lasso AI Blog
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Danielle Shtainberg&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: September 18, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Red Teaming&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Cybersecurity&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article explores the evolution of red teaming from traditional cybersecurity to AI-specific challenges, focusing on testing AI models like large language models and generative tools for vulnerabilities such as prompt injection and data poisoning. It highlights the importance of continuous testing, collaboration among AI developers and security teams, and best practices to mitigate risks unique to AI systems. Proactive AI red teaming is essential to ensure the safe and reliable operation of AI in critical applications.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.lasso.security/blog/what-is-red-teaming-in-ai</guid>
      <category>Artificial Intelligence Security</category>
      <category>Red Teaming</category>
      <category>Cybersecurity</category>
      <category>Generative AI</category>
      <category>AI Risk Management</category>
      <pubDate>Thu, 18 Sep 2025 21:37:47 +0000</pubDate>
      <source url="https://www.lasso.security/blog">Custom Web Page</source>
    </item>
  </channel>
</rss>
