<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>AI Security Digest</title>
    <link>https://kentaroh-toyoda.github.io/ai-security-feed</link>
    <description>Curated AI security insights and articles from various sources</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>AI Security Digest Agent</generator>
    <language>en</language>
    <lastBuildDate>Wed, 17 Sep 2025 21:34:40 +0000</lastBuildDate>
    <item>
      <title>LLM Red Teaming: The Complete Step-By-Step Guide To LLM Safety</title>
      <link>https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Kritin Vongthongsri&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Aug 8, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence Safety&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Large Language Models&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Adversarial Testing&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article provides a comprehensive guide to LLM red teaming, a process designed to identify and mitigate vulnerabilities such as bias, misinformation, and data leakage in Large Language Models through adversarial testing. It emphasizes the importance of red teaming for ensuring model safety, compliance, and reputation protection, and introduces tools like DeepTeam to facilitate effective safety testing. The guide covers best practices, common attacks, and step-by-step implementation strategies for robust LLM security.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.confident-ai.com/blog/red-teaming-llms-a-step-by-step-guide</guid>
      <category>Artificial Intelligence Safety</category>
      <category>Large Language Models</category>
      <category>Adversarial Testing</category>
      <category>AI Ethics and Compliance</category>
      <category>Machine Learning Security</category>
      <pubDate>Wed, 17 Sep 2025 21:34:42 +0000</pubDate>
      <source url="https://www.confident-ai.com/blog">confident-ai.com</source>
    </item>
    <item>
      <title>Using LLMs for Synthetic Data Generation: The Definitive Guide</title>
      <link>https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Kritin Vongthongsri&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Aug 8, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Synthetic Data Generation&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Large Language Models&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Machine Learning Evaluation&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article explores how large language models (LLMs) can be used to generate high-quality synthetic datasets quickly and cost-effectively, bypassing the need for manual data collection and annotation. It covers methods like self-improvement and distillation, the process of evolving synthetic queries from knowledge bases, and provides a practical tutorial using the DeepEval framework to create synthetic data for evaluating LLM systems.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.confident-ai.com/blog/the-definitive-guide-to-synthetic-data-generation-using-llms</guid>
      <category>Synthetic Data Generation</category>
      <category>Large Language Models</category>
      <category>Machine Learning Evaluation</category>
      <category>Data Engineering</category>
      <category>Natural Language Processing</category>
      <pubDate>Wed, 17 Sep 2025 21:34:42 +0000</pubDate>
      <source url="https://www.confident-ai.com/blog">confident-ai.com</source>
    </item>
    <item>
      <title>LLM testing in 2024: Top methods and strategies</title>
      <link>https://www.confident-ai.com/blog/llm-testing-in-2024-top-methods-and-strategies</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Jeffrey Ip&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Aug 8, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Large Language Models&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Testing and Evaluation&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Software Testing Methodologies&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article distinguishes between LLM evaluation and testing, emphasizing that testing focuses on identifying unexpected failures across diverse scenarios. It outlines key LLM testing methods such as unit and functional testing, highlights best practices, and demonstrates how to implement tests using the open-source DeepEval framework. The piece underscores the importance of robust, scalable testing approaches to ensure LLM outputs meet criteria like accuracy, coherence, fairness, and safety.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.confident-ai.com/blog/llm-testing-in-2024-top-methods-and-strategies</guid>
      <category>Large Language Models</category>
      <category>AI Testing and Evaluation</category>
      <category>Software Testing Methodologies</category>
      <category>Machine Learning Tools</category>
      <category>Natural Language Processing</category>
      <pubDate>Wed, 17 Sep 2025 21:34:42 +0000</pubDate>
      <source url="https://www.confident-ai.com/blog">confident-ai.com</source>
    </item>
    <item>
      <title>LLM chatbot evaluation explained: Top chatbot evaluation metrics and testing techniques</title>
      <link>https://www.confident-ai.com/blog/llm-chatbot-evaluation-explained-top-chatbot-evaluation-metrics-and-testing-techniques</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Jeffrey Ip&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Aug 8, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Natural Language Processing&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Chatbot Development&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article explains the importance of evaluating LLM chatbots by considering multi-turn conversations and prior context, which differs from traditional single-turn LLM evaluation. It introduces key chatbot evaluation metrics such as conversation relevancy, role adherence, and knowledge retention, and highlights DeepEval, an open-source framework that facilitates implementing these multi-turn evaluation techniques in code.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.confident-ai.com/blog/llm-chatbot-evaluation-explained-top-chatbot-evaluation-metrics-and-testing-techniques</guid>
      <category>Artificial Intelligence</category>
      <category>Natural Language Processing</category>
      <category>Chatbot Development</category>
      <category>Machine Learning Evaluation</category>
      <category>Software Testing</category>
      <pubDate>Wed, 17 Sep 2025 21:34:42 +0000</pubDate>
      <source url="https://www.confident-ai.com/blog">confident-ai.com</source>
    </item>
    <item>
      <title>LLM-as-a-Judge Simply Explained: The Complete Guide to Run LLM Evals at Scale</title>
      <link>https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Jeffrey Ip&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Aug 21, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Large Language Models&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Evaluation Methods&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Natural Language Processing&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article explains the concept of LLM-as-a-Judge, an automated method for evaluating large language model outputs based on custom criteria such as relevance, helpfulness, faithfulness, bias, and correctness. It highlights the advantages of LLM judges over traditional evaluation metrics and human annotation, describes different types of LLM judges (single-output and pairwise), and discusses techniques to improve their accuracy and reliability. The article also introduces open-source tools like DeepEval for easy implementation and emphasizes the need for careful prompt engineering to mitigate limitations.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.confident-ai.com/blog/why-llm-as-a-judge-is-the-best-llm-evaluation-method</guid>
      <category>Large Language Models</category>
      <category>AI Evaluation Methods</category>
      <category>Natural Language Processing</category>
      <category>Machine Learning Tools</category>
      <category>Automated Quality Assessment</category>
      <pubDate>Wed, 17 Sep 2025 21:34:42 +0000</pubDate>
      <source url="https://www.confident-ai.com/blog">confident-ai.com</source>
    </item>
    <item>
      <title>LLM evaluation metrics: Everything you need for LLM evaluation</title>
      <link>https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Jeffrey Ip&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Sep 1, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Natural Language Processing&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Machine Learning Evaluation&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
The article provides a comprehensive guide to evaluating Large Language Models (LLMs) by exploring various metrics such as correctness, relevance, hallucination, and task completion. It emphasizes the importance of selecting appropriate metrics based on specific use cases and introduces advanced evaluation frameworks like G-Eval and DeepEval, including practical implementation advice. The article also highlights the limitations of traditional metrics and advocates for using LLMs themselves as evaluators for more nuanced assessment.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation</guid>
      <category>Artificial Intelligence</category>
      <category>Natural Language Processing</category>
      <category>Machine Learning Evaluation</category>
      <category>Large Language Models</category>
      <category>Software Development Tools</category>
      <pubDate>Wed, 17 Sep 2025 21:34:42 +0000</pubDate>
      <source url="https://www.confident-ai.com/blog">confident-ai.com</source>
    </item>
    <item>
      <title>GPT-5 Under Fire: Red Teaming OpenAIâ€™s Latest Model Reveals Surprising Weaknesses</title>
      <link>https://splx.ai/blog/gpt-5-red-teaming-results</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: Dorian GranoÅ¡a&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: Aug 8, 2025&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Artificial Intelligence&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Safety and Alignment&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;Machine Learning Models&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
A comprehensive red team evaluation of OpenAI's GPT-5 reveals that despite its advanced capabilities and new safety training strategies, the model's default safety and alignment remain insufficient for enterprise use without robust prompt hardening and runtime protections. Comparisons with GPT-4o show GPT-5 underperforms on hardened benchmarks, highlighting the critical role of infrastructure over model improvements in ensuring safety and trustworthiness. Industry reactions to GPT-5 are mixed, recognizing technical progress but cautioning against overestimating its readiness as an AGI milestone.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://splx.ai/blog/gpt-5-red-teaming-results</guid>
      <category>Artificial Intelligence</category>
      <category>AI Safety and Alignment</category>
      <category>Machine Learning Models</category>
      <category>Enterprise AI Security</category>
      <category>Technology Evaluation</category>
      <pubDate>Wed, 17 Sep 2025 21:34:41 +0000</pubDate>
      <source url="https://splx.ai/blog">splx.ai</source>
    </item>
    <item>
      <title>Where DevSecOps Meets AI Security: TrojAI + JFrog Integration</title>
      <link>https://www.troj.ai/blog/devsecops-ai-security-trojai-jfrog-integration</link>
      <description>&lt;div style="border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin: 8px 0; background-color: #f9f9f9;"&gt;
&lt;div style="font-weight: bold; color: #2c3e50; margin-bottom: 8px;"&gt;
ðŸ“„ Source: Unknown Source
&lt;/div&gt;
&lt;div style="font-size: 0.9em; margin-bottom: 8px;"&gt;
&lt;span style="color: #7f8c8d;"&gt;ðŸ‘¤ Author: TrojAI Team&lt;/span&gt; | &lt;span style="color: #7f8c8d;"&gt;ðŸ“… Date: 2023-07-12&lt;/span&gt;
&lt;/div&gt;
&lt;div style="margin-bottom: 8px;"&gt;
&lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;AI Security&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;DevSecOps&lt;/span&gt; &lt;span style="background-color: #3498db; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;"&gt;CI/CD Integration&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="line-height: 1.6;"&gt;
TrojAI has partnered with JFrog to integrate AI security into the DevSecOps pipeline, enabling automated scanning of AI models for vulnerabilities during CI/CD processes. This integration enhances early threat detection, streamlines security workflows, and provides comprehensive reporting to ensure safer AI deployments across various model formats and frameworks.
&lt;/div&gt;</description>
      <guid isPermaLink="false">https://www.troj.ai/blog/devsecops-ai-security-trojai-jfrog-integration</guid>
      <category>AI Security</category>
      <category>DevSecOps</category>
      <category>CI/CD Integration</category>
      <category>AI Model Vulnerability</category>
      <category>Software Development Lifecycle</category>
      <pubDate>Wed, 17 Sep 2025 21:34:40 +0000</pubDate>
      <source url="https://www.troj.ai/blog">troj.ai</source>
    </item>
  </channel>
</rss>
